{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb79c9b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 Uai, 72.9ms\n",
      "Speed: 6.6ms preprocess, 72.9ms inference, 165.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 22.0ms\n",
      "Speed: 3.7ms preprocess, 22.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 22.0ms\n",
      "Speed: 2.3ms preprocess, 22.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 21.8ms\n",
      "Speed: 2.8ms preprocess, 21.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 21.9ms\n",
      "Speed: 2.5ms preprocess, 21.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 21.9ms\n",
      "Speed: 2.5ms preprocess, 21.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 21.9ms\n",
      "Speed: 2.4ms preprocess, 21.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 22.8ms\n",
      "Speed: 3.0ms preprocess, 22.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 21.8ms\n",
      "Speed: 2.3ms preprocess, 21.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 22.1ms\n",
      "Speed: 2.7ms preprocess, 22.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 21.9ms\n",
      "Speed: 1.8ms preprocess, 21.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 21.8ms\n",
      "Speed: 1.8ms preprocess, 21.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 21.9ms\n",
      "Speed: 1.7ms preprocess, 21.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 21.7ms\n",
      "Speed: 1.8ms preprocess, 21.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 21.8ms\n",
      "Speed: 2.2ms preprocess, 21.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 21.7ms\n",
      "Speed: 2.1ms preprocess, 21.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 21.7ms\n",
      "Speed: 2.0ms preprocess, 21.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 21.8ms\n",
      "Speed: 1.9ms preprocess, 21.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.2ms\n",
      "Speed: 1.9ms preprocess, 20.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.4ms\n",
      "Speed: 1.9ms preprocess, 20.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.2ms\n",
      "Speed: 1.9ms preprocess, 20.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.2ms\n",
      "Speed: 2.3ms preprocess, 20.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.2ms\n",
      "Speed: 2.4ms preprocess, 20.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.2ms\n",
      "Speed: 2.0ms preprocess, 20.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.2ms\n",
      "Speed: 1.8ms preprocess, 20.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.3ms\n",
      "Speed: 2.1ms preprocess, 20.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.4ms\n",
      "Speed: 2.5ms preprocess, 20.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.4ms\n",
      "Speed: 2.7ms preprocess, 20.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.3ms\n",
      "Speed: 1.9ms preprocess, 20.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.2ms\n",
      "Speed: 2.0ms preprocess, 20.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.2ms\n",
      "Speed: 1.7ms preprocess, 20.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.0ms\n",
      "Speed: 2.1ms preprocess, 20.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 20.0ms\n",
      "Speed: 2.5ms preprocess, 20.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 19.9ms\n",
      "Speed: 1.8ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 19.9ms\n",
      "Speed: 2.0ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 19.8ms\n",
      "Speed: 1.8ms preprocess, 19.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 19.9ms\n",
      "Speed: 2.0ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 19.8ms\n",
      "Speed: 2.4ms preprocess, 19.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Uai, 19.9ms\n",
      "Speed: 2.3ms preprocess, 19.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load the pre-trained YOLO model (replace with your own model path)\n",
    "model = YOLO('models/ajax.pt')  # Replace with your trained model path\n",
    "\n",
    "# Load the video\n",
    "video_path = \"demo/d.mp4\"  # Replace with your video file path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create a VideoWriter object for the output video\n",
    "output_path = \"output_video.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "# Process video frame by frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Stop if video ends\n",
    "\n",
    "    # Run YOLO detection on the frame\n",
    "    results = model(frame)\n",
    "\n",
    "    # Plot the results on the frame\n",
    "    for result in results:\n",
    "        frame = result.plot()\n",
    "\n",
    "    # Write the frame with detections to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Show frame (optional)\n",
    "    cv2.imshow('s', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('27'):\n",
    "        break  # Press 'q' to exit\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "#cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee62c6-0f01-4c5e-b72b-9948d158b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install roboflow --user\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"eGFkXZOjYEXe4TfSg5oA\")\n",
    "project = rf.workspace(\"hamza-bmwuj\").project(\"teknofest-etqss-fshad\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1391f716-df54-4243-84f7-157214da02c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
